아래는 사용자의 요구사항을 모두 반영한 최종 기획서이다. 최대한 구체적으로 확정적이며, 모델의 예측 성능 극대화를 우선시하였고, 제안사항은 문서 하단에 별도로 기재한다.  

--------------------------------------------  
**1. 전체 프로젝트 개요**  
- **목표:**  
  - 2년치(약 2년 * 365일 * 24시간 * 60분 ≒ 약 1,051,200개) 비트코인 1분봉 차트 데이터 기반으로 시계열 예측 모델 구축  
  - 모델: Temporal Fusion Transformer(TFT) 기반 (PyTorch 활용)  
  - 예측 목표: 차트 기반(OHLCV + 보조지표)으로 10분 후 비트코인 가격 변동폭(수익률 형태, 정량적 예측)을 예측하는 회귀 모델  
    - 예측 결과(다음 10분간 예측 수익률)가 양수면 상승확률이 높다고 판단, 음수면 하락확률이 높다고 판단 가능  
    - 추후 변동성 예측 같은 추가 출력을 위해 모델 아키텍처 확장 가능 (초기부터 멀티아웃풋 레이어 추가 고려)
  - 감성 점수는 학습 데이터로 사용하지 않음. (뉴스 데이터는 실거래 시 보조지표로만 활용)  
  - 거래소 API: ccxt 사용 (Binance 또는 업비트)  
  - 실제 매매 전략: 예측 결과에 따라 단타 진입/청산 전자동 수행  
  - 웹 UI로 실시간 모니터링 (거래내역, 수익률, 포지션 상태 등)

--------------------------------------------  
**2. 데이터 소스 및 처리**  
- **가격 데이터:**  
  - 거래소: Binance (ccxt로 수집)  
  - 기간: 최근 2년치 1분봉 BTC/USDT 데이터  
  - 파생 특징:  
    - 보조지표 총 5개 사용 (정확히 확정):  
      1) 단기 이동평균(Short MA, 예: 5분)  
      2) 중기 이동평균(Medium MA, 예: 20분)  
      3) 장기 이동평균(Long MA, 예: 60분)  
      4) RSI(14)  
      5) Bollinger Bands(20, 2σ) → 상단/중심/하단선 중 중심선만 특성으로 사용(너무 많은 Feature 방지를 위해)  
    - 결과적으로 OHLCV + (Short MA, Medium MA, Long MA, RSI, Bollinger Middle Line)로 총 1+1+1+1+1=5개의 지표 추가 → OHLCV(5개: Open, High, Low, Close, Volume) + 5개 지표 = 총 10개 특성(입력 시 거래량 포함)

- **뉴스 데이터:**  
  - 출처: NewsAPI(유료/무료키), CoinDesk RSS, CoinTelegraph RSS  
  - 감성 분석:  
    - 허깅페이스(HuggingFace) 사전학습된 감성 모델 사용을 권장 (VaderSentiment 보다 대형 언어 모델 기반 감성 분석 모델이 일반적으로 더 정교하고 도메인 확장성 있음)  
  - 단, 감성데이터는 이번 모델 학습에서는 사용하지 않는다. 추후 실전 매매 시 예측 결과 보정용 참고자료로만 활용.

- **소셜 데이터:**  
  - 사용하지 않음.

- **정규화 방식:**  
  - 가격 및 보조지표: Standard Scaling(Z-Score 정규화) 사용. (평균 0, 표준편차 1로 정규화)

- **슬라이딩 윈도우:**  
  - 입력 윈도우: 과거 72시간(3일, 약 4320분) 데이터를 입력으로 사용  
  - 예측 대상: 10분 후 종가 대비 현재 종가의 변동률(정규화 이전의 원시 종가를 기준으로 변동률 계산 후 모델 입력 전 별도 처리)
  
--------------------------------------------  
**3. 모델 선택**  
- **시계열 예측 모델:**  
  - Temporal Fusion Transformer(TFT) 선택 (참고: https://arxiv.org/abs/1912.09363)  
  - PyTorch로 구현  
  - 입력: (N, T, F) 형태의 텐서 (N: 배치, T: 4320(분), F: 특성 수(OHLCV+5지표 등))  
  - 출력: 단일 스칼라(10분 후 변동률) 또는 추후 멀티 스칼라(추가 변동성예측) 가능  
  - 멀티타겟으로 확장 계획: 초기부터 변동률+변동성 2개를 동시에 예측하는 두 개의 출력 뉴런을 가진 최종 레이어 구성. 변동성 예측은 향후 성능 개선 시 활용 가능.

--------------------------------------------  
**4. 예측 목표 관련 고려사항**  
- 이진분류(상승/하락)로 예측하면 결과가 0.5 근처에서 맴돌 위험 존재. 극단적 확률 예측이 어려울 수 있음.  
- 정량적 예측(변동률 예측)으로 접근하면 모델은 상승/하락 정도를 연속값으로 제공 → 상승 확률 유추 가능(예: 변동률 > 0이면 상승확률 높다고 판단)  
- 변동폭 예측 등 복합전략:  
  - 이번에 학습 시 바로 변동률(정규화된 수익률)을 메인 타겟으로 하고 추가적으로 변동성(표준편차 추정값 등)도 예측하는 멀티아웃풋 모델로 설계해둠.  
  - 추후 변동성 기반 전략(예: 예상 변동폭이 클 때만 포지션 진입 강화)을 추가하려면 모델 학습 시점에서 멀티타겟 구조를 반영해두는 것이 재학습 비용 절감에 도움.

--------------------------------------------  
**5. 하이퍼파라미터 튜닝 (Optuna 적용)**  
- **튜닝 대상 하이퍼파라미터:**  
  1) Learning Rate: 1e-5 ~ 1e-3 사이 로그 스케일  
  2) Hidden Dimension(d_model): 예: 64 ~ 512 사이  
  3) Layer 수: 2 ~ 6개  
  4) Attention Head 수: 2 ~ 8개  
  5) Dropout 비율: 0.0 ~ 0.3 사이  
  6) Batch Size: 16 ~ 128 사이  
- Optuna로 각 Trial 마다 성능(MAE, MSE, RMSE, 예측 정확성 등)을 평가, 가장 좋은 성능 파라미터 선택  
- 성능을 최우선으로 하므로 튜닝 범위 넓게 설정.  
- Early Stopping, ReduceLROnPlateau 등 콜백 적용해 학습 안정화.

--------------------------------------------  
**6. 실행 환경 및 코드 구조**  
- **학습:**  
  - 구글 코랩 프로 환경에서 PyTorch + T4 GPU 활용  
  - 코랩 노트북에서 `!git clone ...` 한 뒤 프로젝트 구조 그대로 가져와 학습  
  - `train.py` (trainer 디렉토리에 위치) 실행 시 `from src.data_loader...`, `from src.model...` 식으로 필요한 모듈 임포트  
  - 모든 하위 모듈은 파이썬 패키지 구조로 구성하여 `__init__.py`를 통한 import 가능하도록 함  
  - Optuna 튜닝 시 `train.py` 내에서 Optuna Study 생성 후, 각 Trial 별로 모델 빌드 및 학습 실행

- **로컬 환경(거래 및 추론):**  
  - Docker 컨테이너로 Python, FastAPI, ccxt 환경 구성  
  - 학습 완료된 모델 파일(`model.pth`)를 로컬로 가져와 `inference.py`에서 추론  
  - FastAPI 서버(`server/main.py`) 실행하면 REST API 제공  
  - `docker-compose up`으로 전체 서비스(서버+UI) 기동 가능하게 구성  
  - `.env` 파일에 API 키, 시크릿키 관리(환경변수로 로딩)

- **폴더 구조(확정):**  
  ```
  project_root/
  │
  ├─ data/
  │   ├─ raw/                # 원본 차트 데이터 (CSV)
  │   ├─ processed/          # 전처리 완료된 데이터셋
  │   └─ indicators/         # 보조지표 계산 결과
  │
  ├─ models/
  │   ├─ checkpoints/        # 훈련 중간 체크포인트
  │   └─ trained/            # 최종 학습된 모델 (model.pth)
  │
  ├─ src/
  │   ├─ configs/            # 설정파일, .env는 여기에 위치(또는 project_root)
  │   ├─ data_loader/        # 가격데이터 로딩, 전처리 코드
  │   ├─ features/           # 지표 계산 함수, 변동률 계산 함수
  │   ├─ model/              # TFT 모델 정의, loss 함수, utils
  │   ├─ trainer/            # train.py, optuna_tune.py (학습 및 튜닝 스크립트)
  │   ├─ strategy/           # 추론 결과 기반 매매전략 로직
  │   ├─ trading/            # ccxt 기반 거래 API 연동 코드
  │   ├─ inference/          # inference.py (실시간 추론 코드)
  │   ├─ server/             # FastAPI 서버 main.py, 라우팅
  │   └─ ui/                 # React 빌드 결과물 (정적 파일)
  │
  ├─ docker/
  │   ├─ Dockerfile          # 도커 이미지 빌드
  │   └─ docker-compose.yml
  │
  ├─ tests/
  │   ├─ unit_tests/
  │   ├─ integration_tests/
  │   └─ backtest/           # 백테스트 스크립트
  │
  └─ requirements.txt         # Python 패키지 목록
  ```

- **코드 실행 방식 예시:**  
  - 학습(코랩):  
    ```bash
    # 코랩 셀 안
    !git clone <repo_url>
    %cd project_root
    !pip install -r requirements.txt
    python src/trainer/train.py  # optuna_tune.py 내에서 튜닝 가능
    ```
  - 로컬 추론/매매:  
    ```bash
    docker-compose up --build
    # server: http://localhost:8000/
    # UI: React 정적 파일 서빙
    # inference.py를 daemon 모드로 실행하거나 서버 내에서 일정 주기로 predict 호출
    ```

--------------------------------------------  
**7. 매매 전략(단타전략) 확정**  
- 예측 결과(10분 후 변동률 예측값):  
  - > 0%: 향후 상승 기대 → 롱 진입  
  - < 0%: 향후 하락 기대 → 숏 진입 또는 현금 유지(현물일 경우 미보유)  
- 포지션 관리:  
  - 진입 후 변동률 +0.5% 이상이면 익절, -0.3% 이하 시 손절 (단타 기준)  
  - 변동성 예측이 추가되면 변동성 높을 때 진입 강도를 높이는 전략 가능  
- 승률, 수익률에 따른 전략 개선: 백테스트 및 실전 모니터링 후 개선

--------------------------------------------  
**8. 웹 UI 표시 정보(확정)**  
- 실시간 가격 차트(1분봉)  
- 현재 포지션(롱/숏, 진입가격, 수량, 미실현손익)  
- 계좌 잔고, 일별 누적 PnL  
- 최근 거래 내역(진입/청산시점, 결과 수익률)  
- 모델 예측값(10분 후 변동률), 변동성 예측값  
- 누적 승률, 일/주/월 평균 수익률, 최대낙폭(MDD), 샤프비율  
- 전략 파라미터(익절/손절폭, 거래량 비율) 제어 기능

--------------------------------------------  
**9. 추가 제안사항**  
- 허깅페이스 감성 모델 vs VaderSentiment:  
  - 허깅페이스 대형언어모델 기반 감성분석이 일반적으로 더 정확하고 최신 트렌드 반영 가능. 성능 우선이면 허깅페이스 모델 추천.  
- 데이터 확장: 필요시 3년치로 확대하여 Transformer 모델 강점 극대화 가능  
- 튜닝 과정: Optuna로 GPU 환경에서 최대한 다양한 시도 수행 후 best 모델 채택

--------------------------------------------

이상으로 최종 기획서 초안이다. 이 설정을 그대로 따라 구현하면 파일 분할 구조에도 불구하고 파이썬 패키지 import 방식으로 모든 모듈이 유기적으로 실행 가능하다. `train.py`를 엔트리포인트로 실행하면, 해당 스크립트 내에서 `src` 하위 모듈들을 import하여 순차적으로 학습 파이프라인을 돌릴 수 있다.

**추가 질문 제안:**  
- 감성 분석을 실시간으로 반영하기 위해서는 어떤 빈도로 감성 점수를 업데이트할 것인가? (추후 실전 적용 시)  
- Transformer 모델 외에 Ensemble 기법(다른 모델 결과 혼합)도 고려할 수 있을까?  
(위는 선택사항이므로 지금 기획안에 바로 반영할 필요는 없음)